<!DOCTYPE html>
<html lang="en-us">
    
    


    <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <link href="https://gmpg.org/xfn/11" rel="profile">
    
    <link rel="canonical" href="http://localhost:1313/essays/2026-02-10-the-problem-with-llms/">
    
    <meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<!-- Enable responsiveness on mobile devices -->
<meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=1">
<meta name="generator" content="Hugo 0.131.0">

    
    
    

<title>The Problem With LLMs • Steven Deobald</title>



  <meta name="twitter:card" content="summary">
  <meta name="twitter:title" content="The Problem With LLMs">
  <meta name="twitter:description" content="Premise Six months ago, a friend of mine, with whom I work on the nonprofit Pariyatti mobile app, sent me this blog post by Vijay Khanna: From Idea to App in 7 Hours. By now, this is a fairly common zero-to-one LLM coding story. (LLM is short for Large Language Model but for the purposes of this essay, we’ll use it as a substitute for what is broadly categorized as “generative AI” in early 2026.">

<meta property="og:url" content="http://localhost:1313/essays/2026-02-10-the-problem-with-llms/">
  <meta property="og:site_name" content="Steven Deobald">
  <meta property="og:title" content="The Problem With LLMs">
  <meta property="og:description" content="Premise Six months ago, a friend of mine, with whom I work on the nonprofit Pariyatti mobile app, sent me this blog post by Vijay Khanna: From Idea to App in 7 Hours. By now, this is a fairly common zero-to-one LLM coding story. (LLM is short for Large Language Model but for the purposes of this essay, we’ll use it as a substitute for what is broadly categorized as “generative AI” in early 2026.">
  <meta property="og:locale" content="en_us">
  <meta property="og:type" content="article">
    <meta property="article:section" content="essays">
    <meta property="article:published_time" content="2026-02-11T00:00:00+00:00">
    <meta property="article:modified_time" content="2026-02-11T00:00:00+00:00">


    






<link rel="stylesheet" href="/scss/hyde-hyde.3081c4981fb69a2783dd36ecfdd0e6ba7a158d4cbfdd290ebce8f78ba0469fc6.css" integrity="sha256-MIHEmB&#43;2mieD3Tbs/dDmunoVjUy/3SkOvOj3i6BGn8Y=">


<link rel="stylesheet" href="/scss/print.2744dcbf8a0b2e74f8a50e4b34e5f441be7cf93cc7de27029121c6a09f9e77bc.css" integrity="sha256-J0Tcv4oLLnT4pQ5LNOX0Qb58&#43;TzH3icCkSHGoJ&#43;ed7w=" media="print">



    <!-- HTML5 shim and Respond.js for IE8 support of HTML5 elements and media queries -->
    <!--[if lt IE 9]>
    <script src="https://oss.maxcdn.com/html5shiv/3.7.3/html5shiv.min.js"></script>
    <script src="https://oss.maxcdn.com/respond/1.4.2/respond.min.js"></script>
    <![endif]-->
    <!-- Icons -->
    <link rel="apple-touch-icon-precomposed" sizes="144x144" href="/apple-touch-icon-144-precomposed.png">
    <link rel="shortcut icon" href="/favicon.png">
    
    
<link rel="stylesheet" href="/css/deobald.css">
<script defer data-domain="deobald.ca" src="https://stati.stic.earth/js/script.js"></script>

</head>


    <body class=" ">
    
<div class="sidebar">
  <div class="container ">
    <div class="sidebar-about">
      <span class="site__title">
        <a href="http://localhost:1313/">Steven Deobald</a>
      </span>
      
      
        <div class="author-image">
          <img src="https://www.gravatar.com/avatar/03e8994ec9679667eb7eabe1138e168e?s=240&d=mp" class="img--circle img--headshot element--center" alt="gravatar">
        </div>
      
      <p class="site__description">
        
      </p>
    </div>
    <div class="collapsible-menu">
      <input type="checkbox" id="menuToggle">
      <label for="menuToggle">Steven Deobald</label>
      <div class="menu-content">
        <div>
	<ul class="sidebar-nav">
		 
		 
			 
				<li>
					<a href="/essays/">
						<span>Essays</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="/reading/">
						<span>Readings</span>
					</a>
				</li>
			 
		 
			 
				<li>
					<a href="/index.xml">
						<span>RSS Feed</span>
					</a>
				</li>
			 
		
	</ul>
</div>

        <section class="social">
  
	<a href="https://fantastic.earth/@deobald" rel="me"><i class="fab fa-mastodon fa-lg" aria-hidden="true"></i></a>
	
  
	<a href="https://bsky.app/profile/deobald.bsky.social" rel="me"><i class="fab fa-bluesky fa-lg" aria-hidden="true"></i></a>
	
	
	
	
	
	<a href="https://github.com/deobald" rel="me"><i class="fab fa-github fa-lg" aria-hidden="true"></i></a>
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	
	<a href="mailto:steven@deobald.ca" rel="me"><i class="fas fa-at fa-lg" aria-hidden="true"></i></a>
	
	
	
	
</section>

      </div>
    </div>
    


  </div>
</div>

        <div class="content container">
            
    
<article>
  <header>
    <h1>The Problem With LLMs</h1>
    
    
<div class="post__meta">
    
    
      <i class="fas fa-calendar-alt"></i> Feb 11, 2026
    
    
    
      
      
          in
          
          
              <a class="badge badge-category" href="/categories/open-source">OPEN SOURCE</a>
              •
          
              <a class="badge badge-category" href="/categories/technology">TECHNOLOGY</a>
              
          
      
    
    
    
    <br/>
    <i class="fas fa-clock"></i> 13 min read
</div>


  </header>
  
  
  <div class="post">
    <h2 id="premise">Premise</h2>
<p>Six months ago, a friend of mine, with whom I work on the nonprofit <a href="https://pariyatti.app">Pariyatti mobile app</a>, sent me this blog post by Vijay Khanna: <a href="https://medium.com/@vijay.khanna.email/from-idea-to-app-in-7-hours-how-i-built-a-vocabulary-app-with-gemini-gemini-cli-and-gemini-code-4c210d7d4bab">From Idea to App in 7 Hours</a>. By now, this is a fairly common zero-to-one LLM coding story. (<em>LLM</em> is short for <em>Large Language Model</em> but for the purposes of this essay, we&rsquo;ll use it as a substitute for what is broadly categorized as &ldquo;generative AI&rdquo; in early 2026. These systems are trained on large bodies of text, images, video, etc., which enable them to produce meaningful responses when prompted.)</p>
<p>The question was posed: could this help us implement new features in the Pariyatti app more quickly?</p>
<p>Indeed it could. But there are ethical concerns to consider before diving into the deep end with LLMs and, unfortunately, they aren&rsquo;t simple concepts to contend with.</p>
<p>Pariyatti&rsquo;s nonprofit mission, it should be noted, specifically incorporates a strict code of ethics, or <em>sīla</em>: not to kill, not to steal, not to engage in sexual misconduct, not to lie, and not to take intoxicants.</p>
<p>In this conversation, two of these <em>sīla</em> are of interest to us.</p>
<h2 id="ethics">Ethics</h2>
<p>The fundamental ethical issue with LLMs is plagiarism. LLMs are, by their very nature, plagiarism machines. In the early days of GitHub Copilot, back before the Copilot brand was subsumed by the Microsoft juggernaut and the cute little sopwith flying helmet-plus-goggles logo was replaced with meaningless rainbow tilde, it would sometimes regurgitate training data <em>verbatim.</em> That&rsquo;s been patched in the years since, but it&rsquo;s important to remember a time &ndash; not that long ago &ndash; that the robots weren&rsquo;t very good at concealing what they were doing.</p>
<p><em>As a quick aside, I am not going to entertain the notion that LLMs are intelligent, for any value of &ldquo;intelligent.&rdquo; They are robots. Programs. Fancy robots and big complicated programs, to be sure &mdash; but computer programs, nonetheless. The rest of this essay will treat them as such. If you are already of the belief that the human mind can be reduced to token regurgitation, you can stop reading here. I&rsquo;m not interested in philosophical thought experiments.</em></p>
<p>Plagiarism requires two halves. The first half of plagiarism is theft. Taking something which is not one&rsquo;s own. It&rsquo;s that peculiar kind of theft where the victim may not even know they&rsquo;re being stolen from: copyright violation. The second half is dishonesty. Plagiarism requires that the thief take the stolen work and <em>also</em> lie about its origins. Most plagiarists <a href="https://youtu.be/yDp3cB5fHXQ">make minor modifications</a> but all plagiarists pass the borrowed work off as their own.</p>
<p>LLMs do both of these things.</p>
<p>LLMs need to eat and to eat they need to steal. Their entire existence is predicated on the theft of copyrighted works and your usage of LLMs is predicated on your willingness to consume pirated work. If it matters to you, these are not exclusively the copyrighted works of large corporations or universities. Especially in the case of source code, it is often the work of individuals. And in the case of open source, that work tends to be licensed in a way that is incompatible with LLM training. LLMs break source code licensing. In the case of text, graphics, audio, and film, the work includes struggling artists. Realistically, other than those few artists who sell burned CDs out of the trunks of their cars to keep their work off the internet completely, it includes <em>every</em> struggling artist.</p>
<p>When you use an LLM, the product of that use is, inherently, a lie. It conceals the trillions of documents it used as source material. And if you claim its output as your own, you not only pander to the lie &mdash; you give it a home in your heart.</p>
<p>If you wouldn&rsquo;t watch a torrented movie or read a downloaded e-book or listen to &ldquo;borrowed&rdquo; MP3s, you shouldn&rsquo;t be using LLMs.</p>
<p>Because I am not in the category of people who adhere strictly to copyright, I&rsquo;ve been experimenting with LLMs for a month. But the lies we tell ourselves are more insideous than a willingness to dip our toes into grey-area theft. Of these two ethical quagmires, the lies concern me the most.</p>
<h2 id="the-positive">The Positive</h2>
<p>Before we get to my concerns, I&rsquo;m going to praise LLMs for the benefits I have witnessed. I haven&rsquo;t seen these arguments made anywhere else, surprisingly, so I hope they are useful to at least a few people.</p>
<p>First, LLMs create accessibility in foreign languages. This is actually the one place we have used LLMs, historically, in the Pariyatti app. Translators are busy and find it easier to review translations than to translate huge CSV files. Even before the ubiquity of programming agents, another volunteer has been translating the UI and content of the Pariyatti app with LLMs. This serves users who would be otherwise unable to read the app in their native language.</p>
<p>Second, LLMs are a form of accessibility for people like me. Due to an eye injury, I had to stop programming back in 2014. I&rsquo;ve taken to puttering, in recent years. But it&rsquo;s still been too much for me to spend all day visually tokenizing source code (which, if you haven&rsquo;t paid attention to what your eyes do while you program, is a large part of what they&rsquo;re up to). Worse yet, I still can&rsquo;t read log files without getting headaches. That needle-in-a-haystack exercise is too painful, no matter how much <code>tail</code> and <code>grep</code> I throw at it.</p>
<p>This is no longer the workflow with an LLM and an agent. Instead, I think about the program, the design, the architecture, the data model, the testing strategy&hellip; and ask a robot in the sky to type it up. The minutiae of programming, which would normally keep my time in the text editor limited to weekends, is almost entirely delivered by the LLM. Limiting screen time allowed me to work through an entire month. The <em>kind</em> of work I did in January will be addressed below, under &ldquo;Problems.&rdquo; But it can&rsquo;t be denied that I was creating software I simply wouldn&rsquo;t have, on my own.</p>
<p>Before we get to those problems, I&rsquo;d like to talk through some of the ways I&rsquo;ve found myself working, and some ways I&rsquo;ve watched others work.</p>
<h2 id="ways-of-working">Ways of Working</h2>
<p>Some friends and I held a 4-hour LLM/agent/orchestrator show-and-tell the other Saturday. There appears to be a spectrum across which developers land.</p>
<p>On one end of the spectrum, we have the most cautious developers. The I&rsquo;ve-never-touched-an-LLM-and-never will folks fit in here, but so do the people who have taken LLMs for a test drive, didn&rsquo;t like it, and decided they&rsquo;re still best used for conversations or banal minutiae, like puking out a one-off bash or python script. In my experience, these people are writing C, C++, or Rust &hellip; or working in some antiquated web framework that cause LLMs a lot of problems, due to lack of documentation and online examples. It matters if they introduce tiny bugs. Their work is careful and deliberate. They&rsquo;ve been at it for 20 years. They&rsquo;re using GLM-4.7 or paying $20/mo for Claude Code Pro.</p>
<p>On the other end of the spectrum, we have the YOLO crowd. They&rsquo;re writing TypeScript, they let the LLM write the test suite, their <code>~/.claude/settings.json</code> is 4 pages long and extremely permissive. <code>brew install</code>? Sure! Whatever you need, Claude. Their work is fast, exploratory, and experimental. The architecture is fragile and the code is sloppy &mdash; intentionally. They&rsquo;re using a pay-as-you-go model and burning tokens worth a mid-level developer salary, per person, every month, on average.</p>
<p>And in the middle are those of us who don&rsquo;t fit in either of these buckets. For instance, I tend to spend a lot of time planning system <a href="https://archive.org/details/working-effectively-with-legacy-code/page/n51/mode/2up">seams</a>, thinking about the data model, worrying about database <a href="https://www.databaserefactoring.com/">schema evolution</a>, API versioning, security without design complexity, and architecture documents that tie it all together. The LLM has no concept of time, the evolution of the system, or the ways the architecture intersects with either of those concepts. That much is still up to a human. I worked with a friend throughout December, and his approach was to YOLO a prompt, let the LLM grind out a bunch of changes, then go through round after round of review until he was satisfied. More than once, it felt like he rewrote everything the LLM spit out. He&rsquo;s working on a medium-sized codebase (OTOO 100,000 LOC). For him, the LLM output was never useless, but it varied in quality from &ldquo;helpful rough skeleton&rdquo; to &ldquo;this can be committed, as-is.&rdquo;</p>
<p>In my solo work, I found it notable how readily my behaviour slid up and down this spectrum. At first, I would bother to read the CSS Claude produced. I stopped caring very quickly. One of the (few) advantages of CSS is that it does manage to separate content from presentation, albeit violently; there&rsquo;s a part of me that knows the CSS could always be rewritten from scratch later. But it currently sits at 3000 lines for a <em>tiny</em> web app and I&rsquo;m sure it would make my frontend developer friends cry to see the crimes committed in there.</p>
<p>It&rsquo;s one thing to do this with CSS. I know CSS. I just hate writing it. But blankly staring at a patch and giving it the &ldquo;LGTM&rdquo; thumbs up just because the app <em>seems</em> to work is a lot more dangerous in a language like, say, Rust. I do not know Rust. I don&rsquo;t hate writing it&hellip; I just can&rsquo;t. So the 700 lines of Rust in my repo scare me many orders of magnitude more than the 3000 lines of CSS, even though my approach to it was the same.</p>
<p>Especially as LLMs are becoming increasingly capable of creating correct code (or, worse, code which very much <em>appears</em> correct), the risk of LGTM&rsquo;ing something dangerous into the repository is growing every week.</p>
<h2 id="problems">Problems</h2>
<p>I was pleased to see someone write about <a href="https://siddhantkhare.com/writing/ai-fatigue-is-real">AI Fatigue</a> this week. In our 4-hour marathon show-and-tell, this was the topic that came up most often amongst folks who were making heavy use of LLMs. I was surprised how many folks were asking each other, &ldquo;so&hellip; how are you <em>feeling</em> with all this?&rdquo;</p>
<p>As one friend put it, LLMs front-load work we&rsquo;re accustomed to performing at intervals, after a small batch of creative work is done: reviewing, QA, evolutionary design&hellip; even refactoring. We&rsquo;re not accustomed to flexing those muscles. Not this often, at least. We wind up playing every role on the team &ndash; from product manager to analyst to iteration manager to engineering manager to tech lead to QA &ndash; in part because we can, in part because we must. It&rsquo;s exhausting.</p>
<p>As the <em>AI Fatigue</em> article points out, this exhaustion comes from doing more work in less time, which leads the average person to think &ldquo;well, I&rsquo;ll just queue up more work then.&rdquo; We don&rsquo;t know how to pace ourselves with these tools. The tools keep getting better so people keep working faster&hellip; but there will come a breaking point. For many, the breaking point has happened already and they&rsquo;re already LGTM&rsquo;ing problematic code into their company&rsquo;s most important repositories.</p>
<p>This is compounded by an effect I like to call <em>The Sweaty Yegge.</em> I mean no disrespect to Steve Yegge, but he seems like an excitable guy and he&rsquo;s definitely too excited about LLMs. <a href="https://steve-yegge.medium.com/bags-and-the-creator-economy-249b924a621a">$GAS</a>, his momentary crypto shill, was preceded by <a href="https://steve-yegge.medium.com/gas-town-emergency-user-manual-cf0e4556d74b">Gas Town</a>, which was preceded by <a href="https://steve-yegge.medium.com/why-i-left-google-to-join-grab-86dfffc0be84">the Asian Gig Economy</a>, which was preceded by <a href="https://steve-yegge.blogspot.com/2006/03/execution-in-kingdom-of-nouns.html">functional programming</a>, I guess. Steve gets excited by things. We all do. But if you find yourself engaged in a <em>Sweaty Yegge</em> episode, I&rsquo;d encourage you to reflect and say to yourself: &ldquo;don&rsquo;t get too excited, too quickly.&rdquo; There will be time to learn these tools and that time doesn&rsquo;t need to be now. The tools will be completely different in six months.</p>
<p>I&rsquo;m aware it&rsquo;s difficult to reconcile a calm outlook on the industry at the moment, given the exponential pace of LLM improvements. But the best of what these programs have to offer us will only come when the next AI winter finally comes to cool things off.</p>
<p>Which brings us to the last bit of LLM psychology: attachment and addiction. These two problematic states of mind are in opposition to one another.</p>
<p>When I say &ldquo;attachment&rdquo;, I am referring to an attachment to the <em>act of programming itself.</em> This is changing, and, for anyone who has tried these tools in the past few months, there is little doubt that it is changing. But for many programmers, the tiny joys are the ones that give hacking all its meaning. The perfect abstraction feels like a perfectly-salted meal. A concise unit test is a flawless wooden inlay. A solid concurrency model is a series of brushstrokes on a painting where the painter wouldn&rsquo;t change a thing. LLMs take these little joys away. It isn&rsquo;t the end of programming. But it is the end of an era. That makes some people sad.</p>
<p>When I say &ldquo;addiction&rdquo;, I am referring to an addiction to <em>getting things done.</em> Especially if you already know what you&rsquo;re doing, LLMs can make you feel superhuman. Like steroids or vyvanse, it&rsquo;s a performance-enhancer. And like steroids or vyvanse, you can get hooked on the performance it enables. One friend, very much on the &ldquo;YOLO as many tokens as the company can afford&rdquo; end of the spectrum, said she had to cut herself off because she found herself prompting with her laptop open on the backs of motorcycles driving through the streets of Bangalore.</p>
<p>The upcoming AI winter won&rsquo;t solve either of these problems. The changes which have come to the profession of programming are permanent changes. Expressing your distate for LLMs or your sadness for the advent of the <a href="https://www.youtube.com/watch?v=wjZofJX0v4M">transformer</a> will be approximately as effective as railing against cars or capitalism. There will be programming &ldquo;purists&rdquo; for many years to come&hellip; but they will need to learn to deal with their sadness and anger, or be consumed by it. Similarly, the shimmer of GTD will consume those who don&rsquo;t learn to ration it out, to pace themselves, and to give themselves time to think.</p>
<h2 id="meta-problems-open-gates">Meta-Problems: Open Gates</h2>
<p>Beyond the copyright violations and the dangerous new psychological landscape, there&rsquo;s a higher-level problem with the current distribution models for LLMs in 2026. There&rsquo;s an opportunity for lock-in that chills me to the bone.</p>
<p>While there are almost no truly &ldquo;open&rdquo; models yet, as we tend to think of <em>open source</em> and <em>open data</em>, the difference between the current crop of &ldquo;open models&rdquo; and fully proprietary models is striking. The proprietary models are given more food with every prompt and, when a model consumes this way, it feeds only itself. A virtuous circle for shareholders. A downward spiral for customers. This could lead to an entirely new era of data gatekeeping and walled gardens.</p>
<p>The leaked Google memo, <a href="https://newsletter.semianalysis.com/p/google-we-have-no-moat-and-neither">&ldquo;We Have No Moat&rdquo;</a> is three years old now, but it still gives me hope that the pace of Chinese companies and academia will ensure no clear winner in the American commercial AI space.</p>
<h2 id="the-future">The Future</h2>
<p>Do I think we should use LLMs at Pariyatti, or any other nonprofit I work with? I&rsquo;m not sure, to be honest. The higher-level ethical concerns of these organizations aren&rsquo;t my jurisdiction. But I do hope this essay provides some food for thought and helps those in management positions consider the topic of LLMs from multiple angles.</p>
<p>Do I think I should use LLMs at work? I need to give further consideration to the accessibility afforded by these tools. Just because I have a disability doesn&rsquo;t make LLMs the right tool choice. But, in all likelihood, this choice will not be mine to make.</p>
<hr>

  </div>
  


  

  
    


</article>


        </div>
        
    

<script defer src="https://use.fontawesome.com/releases/v6.7.1/js/all.js" crossorigin="anonymous"></script>




    



    </body>
</html>
